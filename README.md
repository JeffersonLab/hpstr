updated: 23 March 2020

# Heavy Photon Search Toolkit for Reconstruction

The Heavy Photon Search Toolkit for Reconstruction (hpstr) provides an interface to physics data from the HPS experiment saved in the LCIO format and converts it into an ROOT based format. It also provides tools which can be used to analyze the ROOT format of the data.


## Checkout

```bash
mkdir hpstr
cd hpstr
mkdir src build install
cd src
git clone git@github.com:JeffersonLab/hpstr.git
cd ..
```

## Compilation

```bash
cd build
cmake3 -DCMAKE_INSTALL_PREFIX=../install/ -DLCIO_DIR=$LCIO_DIR  ../src/hpstr/
make -j4 install
```

To compile with debug information, just add -DCMAKE_BUILD_TYPE=Debug to the cmake3 command. After compilation it is necessary to source the setup script in the ```intall/bin``` directory by

```bash
source install/bin/setup.sh 
```
The setup script should be automatically generated by CMake.

## Usage

The basic command string to run hpstr is

```
Usage: hpstr <config.py> [options]

Options:
  -h, --help            show this help message and exit
  -i inFilename, --inFile=inFilename
                        Input filename.
  -d outDir, --outDir=outDir
                        Specify the output directory.
  -o outFilename, --outFile=outFilename
                        Output filename.
```


where ```<config.py>``` is a config file (which are stored in ```hpstr/processors/config/```), followed by various command line options. Different configuration files, might have specific command line options. Please check each configuration file to check which options are available on top of the common ones. 

Hpstr can both run on LCIO files to produce ROOT ntuples, producing the hpstr event with all the objects needed for analysis, and on ROOT ntuples to produce histograms. This can be setup by using the appropriate configuration file. 

### Ntuples production

The configuration to produce ntuples from LCIO files is ```recoTuple_cfg.py```. Typical usage is:
```bash
hpstr recoTuple_cfg.py -i <inLcioFile> -o <outROOTFile>
```

### Making Plots

A working example on how to make some plots out of hpstr ntuple is 

```bash
hpstr anaVtxTuple_cfg.py -i /nfs/slac/g/hps3/users/bravo/data/physrun2016/7800/hps_007800.123_v0_4.2_4.4-SNAPSHOT_rereco.root -o hps_007800.123.root -t 1 
```
This example will run the standard vertex selection on a data file (to specify that this file is data one has to use the ```-t``` flag and passing 0 will tell hpstr that we are processing MonteCarlo. Plots will be produced according to the selections specified. 

### Bump Hunt Analysis

hpstr also includes the HPS 2019 resonance search analysis functionality. A brief description of the capabilities of this code, and how to use it, is included here.

A resonance search job may be called with the following form:

hpstr bhToys_cfg.py -i ${invariantMassDistro.root} -s ${pathToInvariantMassPlot} -d ${outputDirectory} -m ${mass} -p ${backgroundFitPolynomialOrder} -w ${windowSize} -n 0

The variables correspond to:
   ${invariantMassDistro.root}: A ROOT file containing the invariant mass histogram that is to be searched.
   ${pathToInvariantMassPlot}: The path to the invariant mass histogram within the ROOT file.
   ${outputDirectory}: The directory in which to output the result ROOT ntuple.
   ${mass}: The mass to probe. This must be in units of MeV.
   ${backgroundFitPolynomialOrder}: The resonance search uses background fit polynomials of the form 10^(T_n(m)), where T_n(m) is a Chebyshev polynomial of the first kind of order n. This argument specifies n, which may be any value from 0 - 5.
   ${windowSize}: The size of the fit window. This is in units of the mass resolution, so a window size of 5 is equivalent to (5 * massResolution(m)).

This will run a test to determine the p-value, signal yield, and other basic values for the resonance search at the specified point. Multiple jobs must be run to analyze multiple points.

In addition to the above mentioned variables, it is also possible to scale the mass resolution by an arbitrary float by adding the argument "-r ${scalingFactor}".

The resonance search code is also capable of performing toy model analysis. The number of toy models to generate and analyze is specified by the argument "-n ${toyModelCount}". Toy models will automatically be generated from a fit polynomial one order higher than that specified by "-p ${backgroundFitPolynomialOrder}". By default, toy models will be generated with the same number of entries as the input invariant mass histogram. This may be scaled by an integer factor using the argument "-b ${toyModelScalingFactor}". Lastly, signal may be injected into toy models. This is done by adding the argument "--sig ${signalEventCount}", which will add an integer number of signal events at ${mass} using a Gaussian distribution. If a different distribution is desired, it is also possible to specify it using a histogram. This is done with the arguments "--sig_file ${signalShapeHistogramFile.root" --sig_hist ${signalHistogramPath}". Note that the signal histogram should have the same binning as the invariant mass histogram.

## Available Scripts 

The sripts folder in the hpstr repo provides a serie of utilities which some or them are described here. 

### Processing multiple files

The script ```run_jobPool.py``` provides a way to process multiple files with hpstr in parallel in parallel threads. 
Here is an example on how to run it

```bash
python run_jobPool.py -t hpstr -c <configFile.py>  -i <inDir> -z <isData> -o <outDir> -r <root|slcio>
```

where ```-c``` is used to specify the configurationFile for hpstr, ```-i``` and ```-o``` are for specifying the input and output directory respectively, ```-z``` is to choose between data (=1) and MC simulation (=0) input type, and finally ```-r``` is needed to tell hpstr to run on root or slcio files. The script runs one hpstr process for each file on the input folder matching the required extension and places the results in the output directory. Before running the user needs to create a folder ```<outDir>/logs``` otherwise the script fails [will be fixed soon]. 

## Contributing to Hpstr

Fork the repository first. Open an issue to first discuss what needs to be changed and then open a pull request using the issue number. 
